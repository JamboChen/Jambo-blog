{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "openai.api_key = config[\"api_key\"]\n",
    "openai.api_base = config[\"api_base\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "chat_model = \"gpt-35-turbo\"\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "prompt_prefix = \"\"\"\n",
    "你是一个客服，回答用户关于文档的问题。\n",
    "仅使用以下资料提供的事实进行回答。 如果下面没有足够的信息，就说你不知道。不要生成不使用以下资料的答案。\n",
    "\n",
    "资料：\n",
    "{sources}\n",
    "\"\"\"\n",
    "summary_prompt_template = \"\"\"\n",
    "以上是到目前为止的对话记录，下面我将提出一个新问题，需要通过在知识库中搜索相关的条目来回答问题。根据以上的对话记录和下面的新问题，生成一个英文的查询语句，用于在知识库中搜索相关的条目。\n",
    "注意，你只需要回复查询语句，不要加其他任何前缀或后缀。\n",
    "\n",
    "新问题：\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "\n",
    "def get_chat_answer(messages: dict, max_token=1024):\n",
    "    return openai.ChatCompletion.create(\n",
    "        engine=chat_model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_token,\n",
    "    )[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    return openai.Embedding.create(\n",
    "        engine=embed_model,\n",
    "        input=text,\n",
    "    )[\"data\"][\n",
    "        0\n",
    "    ][\"embedding\"]\n",
    "\n",
    "\n",
    "docs = pd.read_csv(\"docs.csv\", converters={\"embedding\": eval})\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Searching: Python Codon 是什么？]\n",
      "Codon 是一个高性能的 Python 编译器，它可以将 Python 代码编译成本地机器代码，而不需要任何运行时开销。Codon 的性能通常与 C/C++ 相当，而且还支持本地多线程，可以实现更高的加速比。此外，Codon 还可以通过插件基础架构进行扩展，可以轻松地集成新的库、编译器优化和关键字等。\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Python Codon 是什么？\"\n",
    "\n",
    "if len(history) == 0:\n",
    "    query = user_input\n",
    "else:\n",
    "    query = get_chat_answer(\n",
    "        history\n",
    "        + [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": summary_prompt_template.format(question=user_input),\n",
    "            }\n",
    "        ],\n",
    "        max_token=32,\n",
    "    )[\"content\"]\n",
    "\n",
    "print(f\"[Searching: {query}]\")\n",
    "query_embedding = get_embedding(query)\n",
    "dot_products = np.dot(np.stack(docs[\"embedding\"].values), query_embedding)\n",
    "top_index = np.argsort(dot_products)[-1:]\n",
    "top_content = (\n",
    "    docs.iloc[top_index][\"content\"].to_string(index=False)\n",
    "    if dot_products[top_index] > 0.8\n",
    "    else \"no information\"\n",
    ")\n",
    "history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "massage = [\n",
    "    {\"role\": \"user\", \"content\": prompt_prefix.format(sources=top_content)},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"好的，我只会根据以上提供的资料提供的内容回答问题，我不会回答不使用资源的内容。\",\n",
    "    },\n",
    "] + history\n",
    "res = get_chat_answer(massage)\n",
    "print(res[\"content\"])\n",
    "history.append(res)\n",
    "print(\"-\" * 50, end=\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
