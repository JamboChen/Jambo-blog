{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "openai.api_key = config[\"api_key\"]\n",
    "openai.api_base = config[\"api_base\"]  # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"  # this may change in the future\n",
    "model = \"gpt-35-turbo\"  # Model deployment name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"5], [2, 3, 4, 5, 1])) == 1\\nassert (pivots([1, 2, 3, 4, 5], [1, 2, 3,\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1681396358,\n",
      "  \"id\": \"cmpl-74sI2SfnVToRLOrsnBkRfVklpRM8D\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 50,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 62\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"1, 2, 3, 4, \"\n",
    "response = openai.Completion.create(\n",
    "    engine=model, prompt=prompt, max_tokens=50, temperature=1, top_p=0.9\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"finish_reason\": \"length\",\n",
      "  \"index\": 0,\n",
      "  \"logprobs\": null,\n",
      "  \"text\": \"5, 6, 7, 8, 9, 10\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"1, 2, 3, 4, \"\n",
    "response = openai.Completion.create(\n",
    "    engine=model, prompt=prompt,  temperature=0.0, stop=[\"11\"]\n",
    ")\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"finish_reason\": \"length\",\n",
      "  \"index\": 0,\n",
      "  \"logprobs\": null,\n",
      "  \"text\": \"5]), 5)\\nprint(count([1, 2, 3,\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"1, 2, 3, 4, \"\n",
    "response = openai.Completion.create(\n",
    "    engine=model, prompt=prompt,  temperature=0.8, stop=[\"11\"]\n",
    ")\n",
    "print(response.choices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-74sJzhz8D47mMlOBUes2Fs4HB5e7W at 0x281a704d610> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Yes, many of the Azure Cognitive Services have support for customer managed keys. For example, Azure Cognitive Services Text Analytics, Azure Cognitive Services Speech Services, and Azure Cognitive Services Translator all support customer managed keys. You can refer to the documentation of the specific Cognitive Service you're interested in to confirm whether customer managed keys are supported or not.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681396479,\n",
       "  \"id\": \"chatcmpl-74sJzhz8D47mMlOBUes2Fs4HB5e7W\",\n",
       "  \"model\": \"gpt-35-turbo\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 69,\n",
       "    \"prompt_tokens\": 58,\n",
       "    \"total_tokens\": 127\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Do other Azure Cognitive Services support this too?\"},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=model, messages=messages  # engine = \"deployment_name\".\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you! How can I assist you today?\n",
      "\n",
      "\n",
      "Please let me know if you have any questions or tasks that you would like me to help with.\n",
      "\n",
      "\n",
      "I'm here to help! Please let me know how I can assist you.\n",
      "\n",
      "\n",
      "If you have any questions, concerns, or tasks that you would like assistance with, please let me know. I am here to help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "while True:\n",
    "    user_input = input()\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,  # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages=conversation,\n",
    "    )\n",
    "\n",
    "    conversation.append(\n",
    "        {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    )\n",
    "    print(\"\\n\" + response.choices[0].message.content + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1680709701,\n",
      "  \"id\": \"chatcmpl-71zev5jegBnNNrmn7LEO7BKvgZBUn\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 31,\n",
      "    \"prompt_tokens\": 28,\n",
      "    \"total_tokens\": 59\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Count to 10. E.g. 1, 2, 3, 4, ...\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"delta\": {\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"finish_reason\": null,\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1680710012,\n",
      "  \"id\": \"chatcmpl-71zjwZk3EB5fLgVup9S1BPZo73JUk\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion.chunk\",\n",
      "  \"usage\": null\n",
      "}\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"\\n\\n\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"1\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"2\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"3\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"4\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"5\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"6\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"7\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fdc10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fe870> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"8\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8bb530> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8feb10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"9\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc110> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \",\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8ffef0> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \" \"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc650> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \"10\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8feb10> JSON: {\n",
      "  \"delta\": {\n",
      "    \"content\": \".\"\n",
      "  },\n",
      "  \"finish_reason\": null,\n",
      "  \"index\": 0\n",
      "}]\n",
      "[<OpenAIObject at 0x1e2ba8fc110> JSON: {\n",
      "  \"delta\": {},\n",
      "  \"finish_reason\": \"stop\",\n",
      "  \"index\": 0\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Count to 10. E.g. 1, 2, 3, 4, ...\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "print(next(response))\n",
    "for chunk in response:\n",
    "    print(chunk.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Count to 10. E.g. 1, 2, 3, 4, ...\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "message = next(response).choices[0].delta\n",
    "content = \"\".join(\n",
    "    [chunk.choices[0].delta.get(\"content\", \"\") for chunk in response]\n",
    ")\n",
    "message.content = content\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def async_completion():\n",
    "    response = await openai.ChatCompletion.acreate(\n",
    "        engine=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Count to 10. E.g. 1, 2, 3, 4, ...\"},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "print(await async_completion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def completion():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Count to 10. E.g. 1, 2, 3, 4, ...\"},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "print(completion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiohttp import ClientSession\n",
    "import asyncio\n",
    "\n",
    "%timeit res = [completion() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit res = await asyncio.gather(*[async_completion() for _ in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3766086101531982\n"
     ]
    }
   ],
   "source": [
    "openai.aiosession.set(ClientSession())\n",
    "res = await asyncio.gather(*[async_completion() for _ in range(10)])\n",
    "await openai.aiosession.get().close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
