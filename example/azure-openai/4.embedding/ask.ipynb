{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用嵌入和对话模型制作一个简单的内部文档助手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "openai.api_key = config[\"api_key\"]\n",
    "openai.api_base = config[\"api_base\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "chat_model = \"gpt-35-turbo\"\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"\n",
    "你是一个客服，回答用户关于文档的问题。\n",
    "仅使用以下资料提供的事实进行回答。 如果下面没有足够的信息，就说你不知道。不要生成不使用以下资料的答案。\n",
    "\n",
    "资料：\n",
    "{sources}\n",
    "\"\"\"\n",
    "summary_prompt_template = \"\"\"\n",
    "以上是到目前为止的对话记录，下面我将提出一个新问题，需要通过在知识库中搜索相关的条目来回答问题。根据以上的对话记录和下面的新问题，生成一个英文的查询语句，用于在知识库中搜索相关的条目。\n",
    "注意，你只需要回复查询语句，不要加其他任何前缀或后缀。\n",
    "\n",
    "新问题：\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_answer(messages, max_token=1024, stream=False):\n",
    "    if stream:\n",
    "        return openai.ChatCompletion.create(\n",
    "            engine=chat_model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=max_token,\n",
    "            stream=True,\n",
    "        )\n",
    "    return openai.ChatCompletion.create(\n",
    "        engine=chat_model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_token,\n",
    "        stream=False,\n",
    "    )[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    return openai.Embedding.create(\n",
    "        engine=embed_model,\n",
    "        input=text,\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "\n",
    "docs = pd.read_csv(\"docs.csv\", converters={\"embedding\": eval})\n",
    "pd.set_option(\"display.max_colwidth\", None) # 取消列宽限制\n",
    "history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\n",
    "\n",
    "if len(history) == 0:\n",
    "    query = user_input\n",
    "else:\n",
    "    query = get_chat_answer(\n",
    "        history\n",
    "        + [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": summary_prompt_template.format(question=user_input),\n",
    "            }\n",
    "        ],\n",
    "        max_token=32,\n",
    "    )[\"content\"]\n",
    "\n",
    "print(f\"[Searching: {query}]\")\n",
    "query_embedding = get_embedding(query)\n",
    "dot_products = np.dot(np.stack(docs[\"embedding\"].values), query_embedding)\n",
    "top_index = np.argsort(dot_products)[-1:]\n",
    "top_content = (\n",
    "    docs.iloc[top_index][\"content\"].to_string(index=False)\n",
    "    if dot_products[top_index] > 0.8\n",
    "    else \"no information\"\n",
    ")\n",
    "history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "massage = [\n",
    "    {\"role\": \"user\", \"content\": prompt_prefix.format(sources=top_content)},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"好的，我只会根据以上提供的资料提供的内容回答问题，我不会回答不使用资源的内容。\",\n",
    "    },\n",
    "] + history\n",
    "\n",
    "res = get_chat_answer(massage, stream=True)\n",
    "next(res)\n",
    "content = \"\"\n",
    "while txt := next(res).choices[0].delta:\n",
    "    text = txt[\"content\"]\n",
    "    print(text, end=\"\")\n",
    "    content += text\n",
    "\n",
    "history.append({\"role\": \"assistant\", \"content\": content})\n",
    "print(\"\\n\" + \"-\" * 50, end=\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
