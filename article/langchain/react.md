在 ChatGPT 开放之初，除了各大公司在 AI 算法方面竞争，还有许多人在研究如何仅通过修改 prompt 就能让 GPT-3 做出更好的回答，这种方法被称为“提示工程（Prompt Engineering）”。如果把 LLM 比喻成一个拥有一般常识的大脑，那么提示工程就是在教它如何思考，从而更有效的结合知识得出答案。像 AutoGPT 就是这样，他通过精心设计的 prompt，就能让 GPT-4 自行完成各种任务。为了让同学们了解这其中的思想，我们先简单介绍一下“思维连”

早在 ChatGPT 诞生之初，就有人发现通过示例引导 GPT 在回答问题时展示其思考过程，可以大大提高回答的准确性。他们将这种方法称为“思维链（Chain-of-Thought）”（**论文地址**）。

![Alt text](https://raw.githubusercontent.com/JamboChen/Jambo-blog/master/img/langchain/react/cot.png)

COT 的过程十分简单，但我想强调的是，为了能够达到更好的效果，在用户看来的一次对话中，可能需要多次使用 LLM，就比如 COT 和上篇教程中用 LLM 去优化资料库的查询语句，甚至在这过程中可能还需要 LLM 判断是否要调用如搜索引擎这样的外部工具。这一整套动作，在 LangChain 中被称为“代理（Agents）”。

# ReAct

ReAct 是一种让 LLM 能够根据逻辑推理和系列行动来实现目标的框架。它可以帮助 LLM 与外部环境进行信息交换和功能协作。ReAct 框架就像是 LLM 的身体，而 LLM 模型就像是它的大脑。ReAct 框架可以为 LLM 提供信息输入、内容输出和决策执行的功能。

ReAct 框架会根据任务目标，自动为 LLM 补充所需的知识和信息，然后让 LLM 做出决策，并执行它的决策。

ReAct 框架也是一种解决复杂问题的方法，它教会 LLM 如何分析问题并寻找答案。这个方法有三个步骤：

1. 思考：根据当前的内容生成下一步的要求和工具。
2. 行动：根据思考结果做出相应的行动。
3. 观察：观察行动的效果。

这三个步骤会不断循环，直到思考步骤判断已经找到答案，并在下一步的行动中给出答案。

LLM 是通过在 prompt 中预先写好的示例来学习如何使用这种思考方法，以及如何操作工具。开发者可以自定义工具的名称、描述和函数，LangChain 会自动为工具生成相应的 prompt。

[1]: https://arxiv.org/abs/2201.11903
[2]: https://arxiv.org/abs/2205.11916